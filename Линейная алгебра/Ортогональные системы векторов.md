#линал 
## Определение
$\vec{a_1}, \dots, \vec{a_k}$ - ортогональная система векторов, если $(\vec{a_i}, \vec{a_j}) = 0 \ \forall i \neq j$.

Ортогональная система называется **ортонормированной**, если $|\vec{a_i}| = 1, \ \forall i$.
## Важное замечание:
В любом линейном подпространстве $L \in E$ существует **ортонормированный базис**, который можно найти с помощью алгоритма **Грама-Шмидта**.
## Алгоритм Грама-Шмидта:
1. Рассмотрим $L = L(\vec{a_1}, \dots, \vec{a_k})$, где $\vec{a_1}, \dots, \vec{a_k}$ - линейно-независимые
2. Найдём в $L$ векторы $\vec{b_1}, \dots, \vec{b_k}$ такие, что $<\vec{a_1}> \ = \ <\vec{b_1}>, \ <\vec{a_1}, \vec{a_2}> \ = \ <\vec{b_1}, \vec{b_2}>, \ \dots$
3. $L = <\vec{b_1}, \dots, \vec{b_k}>$ и $\vec{b_i} \bot \vec{b_j}$
	1.  Шаг 1: $\vec{a_1} = \vec{b_1}$
	2. Шаг 2: Ищем  $\vec{b_2} = \vec{a_2} + \alpha \vec{b_1}$, причём $(\vec{b_1}, \vec{b_2}) = 0$
	3. $(\vec{b_1}, \vec{b_2}) = (\vec{a_2} + \alpha \vec{b_1}, \vec{b_1}) = (\vec{a_2}, \vec{b_2}) + \alpha (\vec{b_1}, \vec{b_2}) = 0$
	4. $\vec{b_2} = \vec{a_2} - \frac{(\vec{a_2}, \vec{b_1})}{(\vec{b_1}, \vec{b_1})} \cdot \vec{b_1}$
	5. Шаг 3: $\alpha = - \frac{(\vec{a_2}, \vec{b_1})}{(\vec{b_1}, \vec{b_1})}$
	6. $\vec{b_3} = \vec{a_3} + \alpha \vec{b_1} + \beta \vec{b_2}$, причём $\vec{b_3} \bot \vec{b_1}, \ \vec{b_3} \bot \vec{b_2}$
	7. $\begin{cases}(\vec{b_3}, \vec{b_1}) = (\vec{a_3}, \vec{b_1}) + \alpha(\vec{b_1}, \vec{b_1}) + \beta(\vec{b_2}, \vec{b_1}) = 0 \\ (\vec{b_3}, \vec{b_2}) = (\vec{a_3}, \vec{b_2}) + \alpha(\vec{b_1}, \vec{b_2}) + \beta(\vec{b_2}, \vec{b_2}) = 0 \end{cases}$
	8. $\alpha = - \frac{(\vec{a_3}, \vec{b_1})}{(\vec{b_1}, \vec{b_1})}, \ \beta = - \frac{\vec{a_3}, \vec{b_2}}{(\vec{b_2}, \vec{b_2})}$
